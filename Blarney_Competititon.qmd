---
title: "Blarney_Stone"
format: html
---

## Quarto



## Running Code


```{r}
library(tidyverse)
library(tidymodels)
library(patchwork)
library(kableExtra)
library(ggridges)
library(marginaleffects)
library(reshape2)
library(knitr)
library(ggplot2)


```


```{r}


data <- read_csv("https://raw.githubusercontent.com/agmath/agmath.github.io/refs/heads/master/data/classification/blarney_data.csv")
comp <- read_csv("https://raw.githubusercontent.com/agmath/agmath.github.io/refs/heads/master/data/classification/blarney_comp.csv")

unregister <- function() {
  env <- foreach:::.foreachGlobals
  rm(list=ls(name=env), pos=env)
}

```


```{r}
data <- data |>
  mutate(kissed = as.factor(kissed))
data_folds <- vfold_cv(data, v = 10, strata = kissed)
my_metrics <- metric_set(accuracy, mn_log_loss)

```

```{r}
bt_spec <- boost_tree(trees = tune()) |>
  set_engine("xgboost") %>% 
  set_mode("classification")
bt_rec <- recipe(kissed ~ ., data = data) |>
  step_rm("id") |>
  step_impute_knn(all_numeric_predictors()) |>
  step_impute_mode(all_nominal_predictors()) |>
  step_dummy(all_nominal_predictors())
bt_wf <- workflow() |>
  add_model(bt_spec) |>
  add_recipe(bt_rec)

 
n_cores <- parallel::detectCores()
cl <- parallel::makeCluster(n_cores - 1, type = "PSOCK")
doParallel::registerDoParallel(cl)
tictoc::tic()
bt_tune_results <- bt_wf %>%
  tune_grid(
    resamples = data_folds,
    metrics = metric_set(mn_log_loss),
    initial = 5,
    control = control_grid(parallel_over = "everything")
  )
tictoc::toc()
doParallel::stopImplicitCluster()
unregister()

```

```{r}
bt_tune_results |>
  augment(data) |>
  mn_log_loss(kissed, .pred_yes)
```

```{r}
my_submission <- bt_fit %>%
  augment(comp) %>%
  rename(kissed = .pred_yes) %>%
  select(id, kissed)
write.csv(my_submission, "submissionJoshAndDillon.csv", row.names = FALSE)
```


```{r}
data <- data |>
  mutate(kissed = as.factor(kissed))
data_folds <- vfold_cv(data, v = 10)
my_metrics <- metric_set(accuracy, mn_log_loss)

```





# SVM Model

```{r}
svm_spec <- svm_poly(cost = tune()) |>
  set_engine("kernlab") %>% 
  set_mode("classification")
svm_rec <- recipe(kissed ~ ., data = data) |>
  step_rm("id") |>
  step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_numeric_predictors())

svm_wf <- workflow() |>
  add_model(svm_spec) |>
  add_recipe(svm_rec)

 
# n_cores <- parallel::detectCores()
# cl <- parallel::makeCluster(n_cores - 1, type = "PSOCK")
# doParallel::registerDoParallel(cl)
# tictoc::tic()
svm_tune_results <- svm_wf %>%
  tune_grid(
    resamples = data_folds,
    metrics = metric_set(mn_log_loss),
    grid = 5
  )
# tictoc::toc()
# doParallel::stopImplicitCluster()
# unregister()

svm_best_param <- svm_tune_results %>% 
  select_best(metric = "mn_log_loss")


svm_final_wf <- svm_wf %>% 
  finalize_workflow(svm_best_param)

svm_fit <- svm_final_wf %>% 
  fit(data)


```

```{r}
svm_fit |>
  augment(data) |>
  accuracy(kissed, .pred_class)
```



```{r}

my_submission <- svm_fit %>%
  augment(comp) %>%
  rename(kissed = .pred_yes) %>%
  select(id, kissed)
write.csv(my_submission, "submissionJoshSVM.csv", row.names = FALSE)
```

