---
title: Analytics Report Shell
author: 
  - name: Joshua, Albert
    email: joshua.albert@snhu.edu
    affiliations: 
      - name: Southern New Hampshire University
date: today
date-format: long
theme: flatly
toc: true
---

```{r global-options, include=FALSE}
library(tidyverse)
library(tidymodels)
library(patchwork)
library(kableExtra)
library(ggridges)
library(marginaleffects)
library(reshape2)
library(knitr)
library(ggplot2)


options(kable_styling_bootstrap_options = c("hover", "striped"))

theme_set(theme_bw(base_size = 14))
```

## Statement of Purpose
```{r}
competition <- read.csv("comp.csv")

data <- read.csv("data.csv")

```
The housing market can be a confusing place with houses having drastically different prices due to different property characteristics. This model is being made to identify the relationship between the price range of a property and its features. An accurate model would be able to output an accurate price range based on certain criteria and give buyers and sellers fair prices for what the home has to offer.


## Executive Summary
```{r}
  
```



## Introduction



## Exploratory Data Analysis


This initial step is attempting to clean the data into more usable data by changing the average school rating into a rounded number.
```{r}
school_edit <- data %>%
  mutate(avgSchoolRating = ifelse(avgSchoolRating <= 10, round(avgSchoolRating,0), round(avgSchoolRating, 1)))

```

This code chunk shows the proportion of each average-school-rating present in all of the houses and shows a histogram to visualize the data.
```{r}
school_edit %>%
  count(avgSchoolRating) %>%
  mutate(proportion = n/sum(n)) %>%
  kable() %>%
  kable_styling()


school_edit%>%
ggplot(aes(x = avgSchoolRating)) +
  geom_histogram(aes(x = avgSchoolRating), color = "black",
fill = "skyblue") + 
  scale_x_continuous(breaks = seq(min(school_edit$avgSchoolRating), max(school_edit$avgSchoolRating), by = 0.5)) +
  labs( 
    title = "Average School Rating Density",
    x = "School Rating",
    y = "Count"
  )

```


```{r}


```

This bar graph shows the number of homes in each price range. This is of course an important parameter to consider when creating a model for finding the price range 
```{r}

school_edit%>%
  ggplot() +
  geom_bar(aes(x = priceRange), color = "black", fill = "red") +
  
  labs(
    x = "Price Range",
    y = "Count"
  )
```
This box plot shows that the there may be a association between the average school rating and the price of the home. The mean for the higher priced homes are closest to the higher average school rating. 
```{r}
school_edit %>%
  mutate(priceRange = fct_reorder(priceRange, avgSchoolRating)) %>%
  ggplot() + 
  geom_boxplot(aes(x = avgSchoolRating, y = priceRange, fill = priceRange),
               show.legend = FALSE) +
  labs(x = "School Rating", y = "Price Range")


```



This is to show a parameter that may not be important to consider. A large proportion (94%) of the homes are single family homes and none of the price ranges have a proportion close to that, meaning it is most likely not a significant factor to consider for the price of the home.
```{r}

school_edit%>%
  count(homeType) %>%
  mutate(proportion = n/sum(n)) %>%
  kable() %>%
  kable_styling()


school_edit%>%
  ggplot() +
  geom_bar(aes(homeType), color = "black", fill = "blue") + 
theme_bw() +  # Use a clean theme
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +
      
labs(
 title = "Home Type Density",
  x = " Home Type",
  y = "Count"
  )  

```


This last plot also shows that there may be a small correlation between the size of the lot and the price range, all of the means increase as the price increases, although very slightly.

```{r}
school_edit %>%
  mutate(priceRange = fct_reorder(priceRange, lotSizeSqFt)) %>%
  ggplot() + 
  geom_boxplot(aes(x = lotSizeSqFt, y = priceRange, fill = priceRange),
               show.legend = FALSE) +
               scale_x_log10() +
  labs(x = "Lot Size (sq/ft)", y = "Price Range")


```




## Model Construction
```{r}

set.seed(347)
data_splits <- initial_split(data, strata = priceRange)

train <- training(data_splits)
test <- testing(data_splits)

set.seed(476)
train_folds <- vfold_cv(train, v = 10, strata = priceRange)

```

```{r}

knn_spec <- nearest_neighbor() %>% 
  set_engine("kknn") %>% 
  set_mode("classification")


knn_rec <- recipe(priceRange ~., data = train) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_rm(all_nominal_predictors()) %>% 
  step_rm(latitude) %>% 
  step_rm(longitude) %>% 
  step_impute_median(all_numeric_predictors()) %>% 
  step_dummy(all_nominal_predictors())


knn_wf <- workflow() %>% 
  add_model(knn_spec) %>% 
  add_recipe(knn_rec)

```


```{r}

knn_cv_results <- knn_wf %>% 
  fit_resamples (
    resamples = train_folds,
    metrics = metric_set(mn_log_loss)
  )


knn_cv_results %>% 
  collect_metrics()

```

```{r}
knn_train_fit <- knn_wf %>% 
  fit(train)

```

```{r}



```


## Ensembles of Data

```{r}

rf_tune_spec <- rand_forest(trees = tune()) %>% 
  set_engine("ranger") %>% 
  set_mode("classification")

rf_tune_rec <- recipe(priceRange ~., data = train) %>% 
  step_rm(description) %>% 
  step_unknown(all_nominal_predictors()) %>% 
  step_novel(all_nominal_predictors()) %>% 
  step_other(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_impute_median(all_numeric_predictors())

rf_tune_wf <- workflow() %>% 
  add_model(rf_tune_spec) %>% 
  add_recipe(rf_tune_rec)

```


```{r}
n_cores <- parallel::detectCores()
cluster <- parallel::makeCluster(n_cores - 1, type = "PSOCK")
doParallel::registerDoParallel(cluster)
tictoc::tic()
rf_tune_results <- rf_tune_wf %>%
  tune_grid(
    grid = 2,
    resamples = train_folds,
    metrics = metric_set(recall)
  )
parallel::stopCluster(cluster)
tictoc::toc()
```

```{r}
rf_tune_results %>% 
  show_best()



```

## Model Interpretation and Inference



## Conclusion



## References
```{r}



```

You can add options to executable code like this

```{r}


```


